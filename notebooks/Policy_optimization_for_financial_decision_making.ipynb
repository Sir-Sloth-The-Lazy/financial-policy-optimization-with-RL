{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Financial Policy Optimization - Colab Runner\n",
        "\n",
        "Use this notebook to run the project on Google Colab (A100 GPU).\n",
        "\n",
        "## 1. Setup\n",
        "Clone the repository and install dependencies."
      ],
      "metadata": {
        "id": "6weafRCB1mdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sir-Sloth-The-Lazy/financial-policy-optimization-with-RL.git\n",
        "%cd financial-policy-optimization-with-RL\n",
        "!pip install -r requirements.txt\n",
        "!pip install d3rlpy gymnasium stable-baselines3 shimmy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyy_0MUu1oaC",
        "outputId": "c2becffb-8b05-4aa8-a31d-cccf7ec28cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'financial-policy-optimization-with-RL'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 51 (delta 13), reused 40 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (51/51), 508.27 KiB | 36.30 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "/content/financial-policy-optimization-with-RL\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.9.0+cu126)\n",
            "Collecting d3rlpy (from -r requirements.txt (line 8))\n",
            "  Downloading d3rlpy-2.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
            "Collecting stable-baselines3 (from -r requirements.txt (line 10))\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting shimmy (from -r requirements.txt (line 11))\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from d3rlpy->-r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from d3rlpy->-r requirements.txt (line 8)) (3.15.1)\n",
            "Collecting gym>=0.26.0 (from d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from d3rlpy->-r requirements.txt (line 8)) (8.3.1)\n",
            "Collecting structlog (from d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading structlog-25.5.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting colorama (from d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting dataclasses-json (from d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting gymnasium (from -r requirements.txt (line 9))\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium->-r requirements.txt (line 9)) (3.1.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium->-r requirements.txt (line 9)) (0.0.4)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.26.0->d3rlpy->-r requirements.txt (line 8)) (0.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 7)) (1.3.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 7)) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy->-r requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading d3rlpy-2.8.1-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading structlog-25.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827727 sha256=5d01e109f6ccb22c63694ea316d6a76030c35c7563cc8250aa5e13675edf742d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/51/6c/9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
            "Successfully built gym\n",
            "Installing collected packages: structlog, mypy-extensions, marshmallow, gymnasium, gym, colorama, typing-inspect, shimmy, dataclasses-json, stable-baselines3, d3rlpy\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.2\n",
            "    Uninstalling gymnasium-1.2.2:\n",
            "      Successfully uninstalled gymnasium-1.2.2\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 d3rlpy-2.8.1 dataclasses-json-0.6.7 gym-0.26.2 gymnasium-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 shimmy-2.0.0 stable-baselines3-2.7.1 structlog-25.5.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: d3rlpy in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.12/dist-packages (2.7.1)\n",
            "Requirement already satisfied: shimmy in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.67.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (3.15.1)\n",
            "Requirement already satisfied: gym>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.26.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (8.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.15.0)\n",
            "Requirement already satisfied: structlog in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (25.5.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.4.6)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.6.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.26.0->d3rlpy) (0.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.5.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->d3rlpy) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->d3rlpy) (0.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.5.0->d3rlpy) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.5.0->d3rlpy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Upload Data\n",
        "Please upload `accepted_2007_to_2018.csv` to `financial-policy-optimization-with-RL/data/raw/`.\n",
        "You can simply drag and drop the file into the Files sidebar on the left."
      ],
      "metadata": {
        "id": "mBjQhQ4c11Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('data/raw/accepted_2007_to_2018.csv'):\n",
        "    print(\"⚠️ Please upload the CSV file!\")\n",
        "else:\n",
        "    print(\"✅ Data found!\")"
      ],
      "metadata": {
        "id": "q_ZTnVts16HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0da512-f2d3-48bd-db49-1616428b5d2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Run Pipeline (Full Dataset)\n",
        "This will process the dataset. Ensure A100 is active for speed."
      ],
      "metadata": {
        "id": "diDe9u6q3BCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/preprocessing.py\n",
        "!python src/rl_preprocessing.py\n",
        "\n",
        "# Risk-Aware Pipeline (Requires DL Model)\n",
        "# 1. Train DL Model first\n",
        "!python src/train_dl.py\n",
        "# 2. Use it to augment features\n",
        "!python src/augment_with_dl.py\n",
        "# 3. Create RL V2 dataset\n",
        "!python src/rl_preprocessing_v2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb-aefro29Q0",
        "outputId": "eaab8425-8896-4bdc-db51-fc4739157a20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /content/financial-policy-optimization-with-RL/data/raw/accepted_2007_to_2018.csv...\n",
            "Fitting preprocessing pipeline...\n",
            "Processed Shape: (93811, 144)\n",
            "Saved processed data to /content/financial-policy-optimization-with-RL/data/processed\n",
            "Loading engineered data for reward calculation...\n",
            "Loading data from /content/financial-policy-optimization-with-RL/data/raw/accepted_2007_to_2018.csv...\n",
            "Saved RL data to /content/financial-policy-optimization-with-RL/data/processed\n",
            "Count: 93811\n",
            "Avg Reward: -1822.63\n",
            "Min Reward: -35000.00\n",
            "Max Reward: 10001.55\n",
            "Device: cuda\n",
            "Epoch 1/10 - Loss: 0.9835 - Val AUC: 0.7318\n",
            "Epoch 2/10 - Loss: 0.9674 - Val AUC: 0.7336\n",
            "Epoch 3/10 - Loss: 0.9673 - Val AUC: 0.7338\n",
            "Epoch 4/10 - Loss: 0.9611 - Val AUC: 0.7351\n",
            "Epoch 5/10 - Loss: 0.9567 - Val AUC: 0.7366\n",
            "Epoch 6/10 - Loss: 0.9540 - Val AUC: 0.7355\n",
            "Epoch 7/10 - Loss: 0.9510 - Val AUC: 0.7331\n",
            "Epoch 8/10 - Loss: 0.9498 - Val AUC: 0.7346\n",
            "Epoch 9/10 - Loss: 0.9451 - Val AUC: 0.7353\n",
            "Epoch 10/10 - Loss: 0.9448 - Val AUC: 0.7336\n",
            "Best Val AUC: 0.7366\n",
            "\n",
            "Final Test Metrics:\n",
            "AUC: 0.7474\n",
            "F1 Score: 0.4565\n",
            "Loading data...\n",
            "Loading DL Model...\n",
            "Running inference to get Prob(Default)...\n",
            "Saved augmented data to /content/financial-policy-optimization-with-RL/data/processed/X_risk_aware.npy. New shape: (93811, 145)\n",
            "Loading engineered data for reward calculation (V2)...\n",
            "Loading data from /content/financial-policy-optimization-with-RL/data/raw/accepted_2007_to_2018.csv...\n",
            "Saved RL V2 (Risk-Aware) data to /content/financial-policy-optimization-with-RL/data/processed\n",
            "Avg Reward (Scaled Penalty): -14304.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RL Grid Search\n",
        "!python src/train_rl_grid_search.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr64TbT73tsn",
        "outputId": "a342231f-75cc-4ebe-eda5-13e36386469c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n",
            "\u001b[2m2025-12-08 16:50.30\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mRegister Shimmy environments. \u001b[0m\n",
            "Loading Data for Grid Search...\n",
            "Loading data from /content/financial-policy-optimization-with-RL/data/raw/accepted_2007_to_2018.csv...\n",
            "Starting Grid Search. Total combinations: 9\n",
            "\u001b[2m2025-12-08 16:50.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(145,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.38\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n",
            "\n",
            "Training cql_p1.0_a0.5...\n",
            "\u001b[2m2025-12-08 16:50.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.39\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.39\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165039\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 0.5}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 100.02it/s, loss=2.17, td_loss=1.77, conservative_loss=0.798]\n",
            "\u001b[2m2025-12-08 16:50.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165039: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004501481771469116, 'time_algorithm_update': 0.005430156707763672, 'loss': 2.167809417009354, 'td_loss': 1.7686118080615998, 'conservative_loss': 0.7983952239751816, 'time_step': 0.009981085777282715}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165039/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 101.13it/s, loss=2.15, td_loss=1.74, conservative_loss=0.814]\n",
            "\u001b[2m2025-12-08 16:50.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165039: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004479713678359985, 'time_algorithm_update': 0.005341267824172974, 'loss': 2.1518994138240815, 'td_loss': 1.7447223465442658, 'conservative_loss': 0.814354137122631, 'time_step': 0.009870314121246337}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:50.59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165039/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:10<00:00, 99.54it/s, loss=2.15, td_loss=1.74, conservative_loss=0.82]\n",
            "\u001b[2m2025-12-08 16:51.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165039: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004549299716949463, 'time_algorithm_update': 0.005427495718002319, 'loss': 2.1513666599988936, 'td_loss': 1.74123479950428, 'conservative_loss': 0.8202637239098549, 'time_step': 0.010027387619018554}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165039/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 100.63it/s, loss=2.15, td_loss=1.74, conservative_loss=0.821]\n",
            "\u001b[2m2025-12-08 16:51.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165039: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004493153810501098, 'time_algorithm_update': 0.005376250982284546, 'loss': 2.148037300944328, 'td_loss': 1.7373604191541672, 'conservative_loss': 0.821353765130043, 'time_step': 0.009919216871261597}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165039/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 102.54it/s, loss=2.15, td_loss=1.73, conservative_loss=0.826]\n",
            "\u001b[2m2025-12-08 16:51.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165039: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004455401420593262, 'time_algorithm_update': 0.005230880260467529, 'loss': 2.143980301260948, 'td_loss': 1.7309432057142258, 'conservative_loss': 0.8260741910934448, 'time_step': 0.009734725952148438}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165039/model_5000.d3\u001b[0m\n",
            "  -> Approval: 92.77%\n",
            "  -> Bad Rate: 79.58%\n",
            "  -> Value ($): -16,464,766\n",
            "\n",
            "Training cql_p1.0_a2.0...\n",
            "\u001b[2m2025-12-08 16:51.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.29\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.29\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165129\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 2.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 102.41it/s, loss=3.27, td_loss=1.85, conservative_loss=0.708]\n",
            "\u001b[2m2025-12-08 16:51.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165129: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004459485292434693, 'time_algorithm_update': 0.005237565994262695, 'loss': 3.267235862016678, 'td_loss': 1.8504522604346276, 'conservative_loss': 0.7083918008208275, 'time_step': 0.009746549129486083}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165129/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 103.24it/s, loss=3.27, td_loss=1.86, conservative_loss=0.709]\n",
            "\u001b[2m2025-12-08 16:51.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165129: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004422729253768921, 'time_algorithm_update': 0.005197987079620361, 'loss': 3.2729309425354005, 'td_loss': 1.8541722084879875, 'conservative_loss': 0.7093793647289276, 'time_step': 0.009668464660644532}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165129/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 102.00it/s, loss=3.25, td_loss=1.83, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:51.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165129: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004440900325775147, 'time_algorithm_update': 0.005296695232391358, 'loss': 3.2517731947898865, 'td_loss': 1.8315514283776284, 'conservative_loss': 0.7101108825802803, 'time_step': 0.0097856764793396}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:51.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165129/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 100.62it/s, loss=3.26, td_loss=1.84, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:52.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165129: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004498923540115356, 'time_algorithm_update': 0.005371977090835572, 'loss': 3.2651263086795805, 'td_loss': 1.8447141479849816, 'conservative_loss': 0.7102060797810554, 'time_step': 0.009920005559921265}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165129/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:10<00:00, 99.81it/s, loss=3.26, td_loss=1.84, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:52.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165129: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0045572612285614015, 'time_algorithm_update': 0.005394269943237304, 'loss': 3.256968928337097, 'td_loss': 1.8365988169312477, 'conservative_loss': 0.7101850543022156, 'time_step': 0.010000751256942749}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165129/model_5000.d3\u001b[0m\n",
            "  -> Approval: 95.24%\n",
            "  -> Bad Rate: 85.74%\n",
            "  -> Value ($): -19,724,757\n",
            "\n",
            "Training cql_p1.0_a10.0...\n",
            "\u001b[2m2025-12-08 16:52.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.19\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.19\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165219\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.19\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 10.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 101.70it/s, loss=8.85, td_loss=1.9, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:52.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165219: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0044957764148712154, 'time_algorithm_update': 0.005270713329315185, 'loss': 8.846321990966796, 'td_loss': 1.9039397161602973, 'conservative_loss': 0.6942382281422615, 'time_step': 0.009814996480941772}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.29\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165219/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 101.41it/s, loss=8.85, td_loss=1.91, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:52.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165219: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004526063203811646, 'time_algorithm_update': 0.00526690936088562, 'loss': 8.849476034641265, 'td_loss': 1.9082750267386437, 'conservative_loss': 0.6941200991272927, 'time_step': 0.009843024492263795}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.39\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165219/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 102.34it/s, loss=8.83, td_loss=1.89, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:52.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165219: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004467137098312378, 'time_algorithm_update': 0.005237082958221436, 'loss': 8.834269739151, 'td_loss': 1.892635884642601, 'conservative_loss': 0.6941633843183518, 'time_step': 0.0097536940574646}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.49\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165219/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 101.95it/s, loss=8.84, td_loss=1.9, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:52.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165219: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004467565298080445, 'time_algorithm_update': 0.0052755622863769535, 'loss': 8.837844479560852, 'td_loss': 1.8967849822044374, 'conservative_loss': 0.6941059522628784, 'time_step': 0.009791465759277343}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:52.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165219/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 101.43it/s, loss=8.83, td_loss=1.89, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:53.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165219: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0044549558162689205, 'time_algorithm_update': 0.005337321043014527, 'loss': 8.835842598438264, 'td_loss': 1.8949367541074753, 'conservative_loss': 0.6940905846357346, 'time_step': 0.009840368509292603}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165219/model_5000.d3\u001b[0m\n",
            "  -> Approval: 91.59%\n",
            "  -> Bad Rate: 77.21%\n",
            "  -> Value ($): -15,239,616\n",
            "\u001b[2m2025-12-08 16:53.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(145,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n",
            "\n",
            "Training cql_p2.0_a0.5...\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165315\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 0.5}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 101.54it/s, loss=3.72, td_loss=3.32, conservative_loss=0.799]\n",
            "\u001b[2m2025-12-08 16:53.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165315: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004525238513946533, 'time_algorithm_update': 0.005255855560302734, 'loss': 3.7178688600063325, 'td_loss': 3.318299950480461, 'conservative_loss': 0.7991378093361855, 'time_step': 0.009830220460891723}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165315/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 102.04it/s, loss=3.7, td_loss=3.29, conservative_loss=0.814]\n",
            "\u001b[2m2025-12-08 16:53.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165315: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004481707811355591, 'time_algorithm_update': 0.0052506749629974364, 'loss': 3.7023515936136246, 'td_loss': 3.2953244367837904, 'conservative_loss': 0.8140543141365051, 'time_step': 0.009782017230987549}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165315/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 102.01it/s, loss=3.71, td_loss=3.3, conservative_loss=0.82]\n",
            "\u001b[2m2025-12-08 16:53.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165315: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004519178867340088, 'time_algorithm_update': 0.005218068361282349, 'loss': 3.705677437186241, 'td_loss': 3.2955664254426957, 'conservative_loss': 0.8202220264673233, 'time_step': 0.009784905195236206}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165315/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 100.51it/s, loss=3.71, td_loss=3.3, conservative_loss=0.821]\n",
            "\u001b[2m2025-12-08 16:53.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165315: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00454899525642395, 'time_algorithm_update': 0.005332533597946167, 'loss': 3.7046160516738893, 'td_loss': 3.294245669722557, 'conservative_loss': 0.8207407615184784, 'time_step': 0.009930557250976562}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:53.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165315/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 100.28it/s, loss=3.7, td_loss=3.28, conservative_loss=0.832]\n",
            "\u001b[2m2025-12-08 16:54.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165315: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004550483226776123, 'time_algorithm_update': 0.005352830171585083, 'loss': 3.6944882386922835, 'td_loss': 3.27844778573513, 'conservative_loss': 0.8320809074044228, 'time_step': 0.00995362401008606}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.04\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165315/model_5000.d3\u001b[0m\n",
            "  -> Approval: 94.46%\n",
            "  -> Bad Rate: 82.69%\n",
            "  -> Value ($): -17,921,889\n",
            "\n",
            "Training cql_p2.0_a2.0...\n",
            "\u001b[2m2025-12-08 16:54.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.05\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165405\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.05\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 2.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:10<00:00, 99.92it/s, loss=4.83, td_loss=3.42, conservative_loss=0.708]\n",
            "\u001b[2m2025-12-08 16:54.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165405: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004543450355529785, 'time_algorithm_update': 0.005396174907684326, 'loss': 4.835321081876755, 'td_loss': 3.4184924778938295, 'conservative_loss': 0.7084143018722534, 'time_step': 0.009989588022232055}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165405/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 100.03it/s, loss=4.78, td_loss=3.37, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:54.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165405: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004537225484848023, 'time_algorithm_update': 0.005390827894210816, 'loss': 4.783417383670807, 'td_loss': 3.36415965282917, 'conservative_loss': 0.709628860771656, 'time_step': 0.009978058338165284}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165405/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 100.72it/s, loss=4.83, td_loss=3.41, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:54.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165405: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0045068726539611815, 'time_algorithm_update': 0.005352806091308593, 'loss': 4.82932453417778, 'td_loss': 3.409622709274292, 'conservative_loss': 0.7098509153723717, 'time_step': 0.009909837722778321}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165405/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:10<00:00, 99.86it/s, loss=4.81, td_loss=3.39, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:54.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165405: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004546210765838623, 'time_algorithm_update': 0.005396912813186646, 'loss': 4.810112029552459, 'td_loss': 3.3898591928482054, 'conservative_loss': 0.7101264210343361, 'time_step': 0.009994520425796509}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.45\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165405/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 101.77it/s, loss=4.83, td_loss=3.41, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:54.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165405: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004503401041030884, 'time_algorithm_update': 0.005255302429199219, 'loss': 4.82757017326355, 'td_loss': 3.406964689850807, 'conservative_loss': 0.7103027376532555, 'time_step': 0.009808143615722657}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.55\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165405/model_5000.d3\u001b[0m\n",
            "  -> Approval: 92.73%\n",
            "  -> Bad Rate: 79.54%\n",
            "  -> Value ($): -16,463,485\n",
            "\n",
            "Training cql_p2.0_a10.0...\n",
            "\u001b[2m2025-12-08 16:54.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165456\u001b[0m\n",
            "\u001b[2m2025-12-08 16:54.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 10.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 100.46it/s, loss=10.4, td_loss=3.45, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:55.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165456: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004548411846160888, 'time_algorithm_update': 0.005337343692779541, 'loss': 10.391006765365601, 'td_loss': 3.4487698541879652, 'conservative_loss': 0.6942236894965171, 'time_step': 0.009936042547225953}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.06\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165456/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:10<00:00, 99.01it/s, loss=10.4, td_loss=3.43, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:55.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165456: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00464167857170105, 'time_algorithm_update': 0.0053886032104492184, 'loss': 10.374275122642517, 'td_loss': 3.4326019787788393, 'conservative_loss': 0.6941673122644424, 'time_step': 0.0100810866355896}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165456/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:10<00:00, 97.90it/s, loss=10.4, td_loss=3.44, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:55.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165456: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004628851175308228, 'time_algorithm_update': 0.0055143005847930904, 'loss': 10.382187647819519, 'td_loss': 3.4406553614139557, 'conservative_loss': 0.6941532269716263, 'time_step': 0.010195112943649292}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165456/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:10<00:00, 99.10it/s, loss=10.4, td_loss=3.45, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:55.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165456: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004567337512969971, 'time_algorithm_update': 0.005454874038696289, 'loss': 10.394303149223328, 'td_loss': 3.4531226878166197, 'conservative_loss': 0.6941180445551872, 'time_step': 0.01007267951965332}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165456/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 100.20it/s, loss=10.4, td_loss=3.48, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:55.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165456: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004508480310440064, 'time_algorithm_update': 0.005403885126113892, 'loss': 10.41481976699829, 'td_loss': 3.473792018175125, 'conservative_loss': 0.6941027755737305, 'time_step': 0.009961884260177613}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.46\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165456/model_5000.d3\u001b[0m\n",
            "  -> Approval: 95.70%\n",
            "  -> Bad Rate: 89.72%\n",
            "  -> Value ($): -21,319,876\n",
            "\u001b[2m2025-12-08 16:55.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(145,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n",
            "\n",
            "Training cql_p5.0_a0.5...\n",
            "\u001b[2m2025-12-08 16:55.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.53\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.53\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165553\u001b[0m\n",
            "\u001b[2m2025-12-08 16:55.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 0.5}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 100.97it/s, loss=8.42, td_loss=8.02, conservative_loss=0.797]\n",
            "\u001b[2m2025-12-08 16:56.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165553: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0045156762599945065, 'time_algorithm_update': 0.005320497035980224, 'loss': 8.421098804950715, 'td_loss': 8.02254027414322, 'conservative_loss': 0.7971170795559883, 'time_step': 0.009885755777359008}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165553/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 101.42it/s, loss=8.37, td_loss=7.97, conservative_loss=0.813]\n",
            "\u001b[2m2025-12-08 16:56.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165553: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0045215685367584225, 'time_algorithm_update': 0.0052713449001312255, 'loss': 8.376167651176452, 'td_loss': 7.969444318294525, 'conservative_loss': 0.8134466599822044, 'time_step': 0.009842468023300171}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165553/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 101.14it/s, loss=8.4, td_loss=7.99, conservative_loss=0.82]\n",
            "\u001b[2m2025-12-08 16:56.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165553: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004523372650146485, 'time_algorithm_update': 0.005295983076095581, 'loss': 8.398299112796783, 'td_loss': 7.988214950561524, 'conservative_loss': 0.8201683155298233, 'time_step': 0.009869220733642579}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165553/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 101.33it/s, loss=8.36, td_loss=7.94, conservative_loss=0.825]\n",
            "\u001b[2m2025-12-08 16:56.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165553: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004511671304702759, 'time_algorithm_update': 0.005288444757461548, 'loss': 8.366723697423934, 'td_loss': 7.95429333281517, 'conservative_loss': 0.8248607199788094, 'time_step': 0.009850516557693482}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165553/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 101.49it/s, loss=8.38, td_loss=7.97, conservative_loss=0.829]\n",
            "\u001b[2m2025-12-08 16:56.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165553: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004498920202255249, 'time_algorithm_update': 0.005286185503005981, 'loss': 8.383459819316863, 'td_loss': 7.969075267791748, 'conservative_loss': 0.828769121170044, 'time_step': 0.009835612535476684}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165553/model_5000.d3\u001b[0m\n",
            "  -> Approval: 95.05%\n",
            "  -> Bad Rate: 84.49%\n",
            "  -> Value ($): -18,212,930\n",
            "\n",
            "Training cql_p5.0_a2.0...\n",
            "\u001b[2m2025-12-08 16:56.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.43\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.43\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165643\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 2.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 103.37it/s, loss=9.56, td_loss=8.15, conservative_loss=0.708]\n",
            "\u001b[2m2025-12-08 16:56.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165643: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0044626307487487795, 'time_algorithm_update': 0.005144704341888428, 'loss': 9.544233374595642, 'td_loss': 8.127803217887879, 'conservative_loss': 0.7082150735259056, 'time_step': 0.00965608310699463}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:56.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165643/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 102.22it/s, loss=9.6, td_loss=8.18, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:57.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165643: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004491640567779541, 'time_algorithm_update': 0.005224097013473511, 'loss': 9.60459387922287, 'td_loss': 8.185491604804993, 'conservative_loss': 0.7095511356592178, 'time_step': 0.00976509928703308}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165643/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 101.77it/s, loss=9.55, td_loss=8.13, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:57.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165643: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0044880383014678955, 'time_algorithm_update': 0.005271640777587891, 'loss': 9.550195483922959, 'td_loss': 8.129825256347656, 'conservative_loss': 0.7101851175427437, 'time_step': 0.009808640480041503}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.12\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165643/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:09<00:00, 100.97it/s, loss=9.56, td_loss=8.14, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:57.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165643: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004520340204238892, 'time_algorithm_update': 0.005316447496414184, 'loss': 9.551790275096893, 'td_loss': 8.131567006826401, 'conservative_loss': 0.7101116334199905, 'time_step': 0.009886281967163086}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.22\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165643/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:09<00:00, 101.34it/s, loss=9.48, td_loss=8.06, conservative_loss=0.71]\n",
            "\u001b[2m2025-12-08 16:57.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165643: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004483856916427612, 'time_algorithm_update': 0.005317583084106446, 'loss': 9.48103926706314, 'td_loss': 8.060840329170228, 'conservative_loss': 0.7100994740128517, 'time_step': 0.009850110054016113}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165643/model_5000.d3\u001b[0m\n",
            "  -> Approval: 94.04%\n",
            "  -> Bad Rate: 82.41%\n",
            "  -> Value ($): -17,316,816\n",
            "\n",
            "Training cql_p5.0_a10.0...\n",
            "\u001b[2m2025-12-08 16:57.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(145,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.33\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.33\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DiscreteCQL_20251208165733\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.33\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [145], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 256, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 0.0003, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 10.0}}}\u001b[0m\n",
            "Epoch 1/5: 100% 1000/1000 [00:09<00:00, 100.64it/s, loss=15.1, td_loss=8.16, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:57.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165733: epoch=1 step=1000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004558380365371704, 'time_algorithm_update': 0.005309370040893555, 'loss': 15.098415197372436, 'td_loss': 8.15495462322235, 'conservative_loss': 0.6943460579514503, 'time_step': 0.009917905807495117}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m1000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165733/model_1000.d3\u001b[0m\n",
            "Epoch 2/5: 100% 1000/1000 [00:09<00:00, 100.02it/s, loss=15.1, td_loss=8.17, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:57.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165733: epoch=2 step=2000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004572758913040161, 'time_algorithm_update': 0.005355142116546631, 'loss': 15.099810754776001, 'td_loss': 8.158804690361023, 'conservative_loss': 0.694100604891777, 'time_step': 0.009979091644287109}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m2000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:57.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165733/model_2000.d3\u001b[0m\n",
            "Epoch 3/5: 100% 1000/1000 [00:09<00:00, 100.04it/s, loss=15.1, td_loss=8.13, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:58.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165733: epoch=3 step=3000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0045592341423034664, 'time_algorithm_update': 0.005367324113845825, 'loss': 15.064627561569214, 'td_loss': 8.123126240253448, 'conservative_loss': 0.694150129199028, 'time_step': 0.009977628707885742}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m3000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:58.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165733/model_3000.d3\u001b[0m\n",
            "Epoch 4/5: 100% 1000/1000 [00:10<00:00, 99.34it/s, loss=15.1, td_loss=8.19, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:58.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165733: epoch=4 step=4000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004557045698165893, 'time_algorithm_update': 0.0054393470287323, 'loss': 15.1282528591156, 'td_loss': 8.187647586584092, 'conservative_loss': 0.6940605250597001, 'time_step': 0.01004770302772522}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m4000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:58.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165733/model_4000.d3\u001b[0m\n",
            "Epoch 5/5: 100% 1000/1000 [00:10<00:00, 99.25it/s, loss=15.1, td_loss=8.19, conservative_loss=0.694]\n",
            "\u001b[2m2025-12-08 16:58.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDiscreteCQL_20251208165733: epoch=5 step=5000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.004555423736572265, 'time_algorithm_update': 0.005451299667358398, 'loss': 15.140050295829774, 'td_loss': 8.199150722503662, 'conservative_loss': 0.6940899560451508, 'time_step': 0.010056720733642579}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m5000\u001b[0m\n",
            "\u001b[2m2025-12-08 16:58.23\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DiscreteCQL_20251208165733/model_5000.d3\u001b[0m\n",
            "  -> Approval: 93.46%\n",
            "  -> Bad Rate: 81.33%\n",
            "  -> Value ($): -17,235,364\n",
            "\n",
            "--- Grid Search Complete ---\n",
            "   Penalty  Alpha  Approval_Rate  Bad_Approval_Rate  Policy_Value_USD\n",
            "2      1.0   10.0       0.915932           0.772125     -1.523962e+07\n",
            "4      2.0    2.0       0.927302           0.795414     -1.646348e+07\n",
            "0      1.0    0.5       0.927658           0.795772     -1.646477e+07\n",
            "8      5.0   10.0       0.934551           0.813329     -1.723536e+07\n",
            "7      5.0    2.0       0.940378           0.824077     -1.731682e+07\n",
            "3      2.0    0.5       0.944642           0.826944     -1.792189e+07\n",
            "6      5.0    0.5       0.950540           0.844858     -1.821293e+07\n",
            "1      1.0    2.0       0.952388           0.857399     -1.972476e+07\n",
            "5      2.0   10.0       0.957007           0.897169     -2.131988e+07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3622H_-K3x5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}